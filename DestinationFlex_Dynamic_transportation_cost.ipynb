{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pykalman\n",
        "!pip install pyreadr"
      ],
      "metadata": {
        "id": "0omgc7fdLzw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from pykalman import KalmanFilter\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/NG.csv')\n",
        "data = data.dropna(axis=1, how='all')\n",
        "data = data.dropna(axis=0, how='all')\n",
        "# Reverse the DataFrame:\n",
        "data = data.iloc[::-1]\n",
        "# Reset the index:\n",
        "data = data.reset_index(drop=True)\n",
        "transport_data = pd.read_csv('/content/transport_to_asia.csv') #Transport prices Europe-Asia\n",
        "\n",
        "\n",
        "# Convert 'Date' columns of both dataframes to datetime format\n",
        "transport_data['Date'] = pd.to_datetime(transport_data['Date'], format='%d/%m/%Y')\n",
        "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%Y')\n",
        "\n",
        "# Merge the dataframes on the 'Date' column using a left join\n",
        "combined_data = data.merge(transport_data, on='Date', how='left')\n",
        "\n",
        "# Interpolate missing values for 'Asia' column\n",
        "combined_data['Asia'] = combined_data['Asia'].interpolate()\n",
        "\n",
        "# combined_data = combined_data.drop(combined_data.tail(252*2).index)"
      ],
      "metadata": {
        "id": "b_iUgH_JLvBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPYuGWERLsED"
      },
      "outputs": [],
      "source": [
        "#MWH DATA\n",
        "\n",
        "dt = 1/252\n",
        "num_simulations = 10000\n",
        "discount_rate = 0.05\n",
        "length = 252*5\n",
        "correlation_matrix = combined_data['JKM'].tail(length).corr(combined_data['TTF'].tail(length))\n",
        "corr_jp_asia = combined_data['JKM'].tail(length).corr(combined_data['Asia'].tail(length))\n",
        "corr_de_asia = combined_data['TTF'].tail(length).corr(combined_data['Asia'].tail(length))\n",
        "\n",
        "\n",
        "\n",
        "def ornstein_uhlenbeck_process_three(params_JP, params_DE, params_ASIA, S0_JP, S0_DE, S0_ASIA, dt, num_steps, num_simulations, correlation_matrix):\n",
        "    theta_JP, mu_JP, sigma_JP = params_JP\n",
        "    theta_DE, mu_DE, sigma_DE = params_DE\n",
        "    theta_ASIA, mu_ASIA, sigma_ASIA = params_ASIA\n",
        "\n",
        "    # Prices matrices\n",
        "    S_t_JP = np.zeros((num_simulations, num_steps))\n",
        "    S_t_JP[:, 0] = S0_JP\n",
        "    S_t_DE = np.zeros((num_simulations, num_steps))\n",
        "    S_t_DE[:, 0] = S0_DE\n",
        "    S_t_ASIA = np.zeros((num_simulations, num_steps))\n",
        "    S_t_ASIA[:, 0] = S0_ASIA\n",
        "\n",
        "    uncorrelated_random_variables = np.random.normal(size=(num_simulations, num_steps, 3))\n",
        "    cov = np.array([[1, correlation_matrix, corr_jp_asia],\n",
        "                [correlation_matrix, 1, corr_de_asia],\n",
        "                [corr_jp_asia, corr_de_asia, 1]])\n",
        "\n",
        "    L = np.linalg.cholesky(cov)\n",
        "    correlated_random_variables = np.matmul(uncorrelated_random_variables, L.T)\n",
        "\n",
        "    for i in range(1, num_steps):\n",
        "        # For JP\n",
        "        dW_JP = correlated_random_variables[:, i, 0] * np.sqrt(dt)\n",
        "        S_t_JP[:, i] = S_t_JP[:, i - 1] + theta_JP * (mu_JP - S_t_JP[:, i - 1]) * dt + sigma_JP * dW_JP\n",
        "        S_t_JP[:, i] = np.maximum(S_t_JP[:, i], 1)\n",
        "\n",
        "        # For DE\n",
        "        dW_DE = correlated_random_variables[:, i, 1] * np.sqrt(dt)\n",
        "        S_t_DE[:, i] = S_t_DE[:, i - 1] + theta_DE * (mu_DE - S_t_DE[:, i - 1]) * dt + sigma_DE * dW_DE\n",
        "        S_t_DE[:, i] = np.maximum(S_t_DE[:, i], 1)\n",
        "\n",
        "        # For ASIA\n",
        "        dW_ASIA = correlated_random_variables[:, i, 2] * np.sqrt(dt)\n",
        "        S_t_ASIA[:, i] = S_t_ASIA[:, i - 1] + theta_ASIA * (mu_ASIA - S_t_ASIA[:, i - 1]) * dt + sigma_ASIA * dW_ASIA\n",
        "        S_t_ASIA[:, i] = np.maximum(S_t_ASIA[:, i], 1)\n",
        "\n",
        "    return S_t_JP, S_t_DE, S_t_ASIA\n",
        "\n",
        "# Function to estimate parameters using Kalman Filter\n",
        "def estimate_parameters(prices, dt):\n",
        "    # Remove any invalid or missing data points\n",
        "    prices = prices.dropna()\n",
        "\n",
        "    # Define the Kalman Filter\n",
        "    kf = KalmanFilter(transition_matrices=[1],\n",
        "                      observation_matrices=[1],\n",
        "                      initial_state_mean=np.mean(prices),\n",
        "                      initial_state_covariance=np.std(prices),\n",
        "                      observation_covariance=1,\n",
        "                      transition_covariance=0.01)\n",
        "\n",
        "    # Use the observations to estimate the model parameters\n",
        "    state_means, _ = kf.filter(prices.values)\n",
        "\n",
        "    theta = 1 - state_means[:-1] / state_means[1:]\n",
        "    mu = state_means[1:] / (1 - theta)\n",
        "    sigma = np.sqrt(np.var(state_means[1:] - theta * state_means[:-1]))\n",
        "\n",
        "    # Return the mean of each parameter\n",
        "    return np.mean(theta), np.mean(mu), np.mean(sigma)\n",
        "\n",
        "# Function to calculate the payoff of the destination flexibility option\n",
        "def calculate_option_payoff(prices_JP, prices_DE, transportation_cost_simulated):\n",
        "    return np.maximum(prices_DE - prices_JP - transportation_cost_simulated, 0)\n",
        "\n",
        "def calculate_option_value(params_JP, params_DE, params_ASIA, S0_JP, S0_DE, S0_ASIA, dt, num_steps, num_simulations, discount_rate, correlation_matrix):\n",
        "    prices_JP, prices_DE, transportation_costs = ornstein_uhlenbeck_process_three(params_JP, params_DE, params_ASIA, S0_JP, S0_DE, S0_ASIA, dt, num_steps, num_simulations, correlation_matrix)\n",
        "    option_values = []\n",
        "    option_values_per_step = np.zeros((num_simulations, num_steps))\n",
        "    for i in range(num_simulations):\n",
        "        payoff = calculate_option_payoff(prices_JP[i], prices_DE[i], transportation_costs[i])\n",
        "        option_value = np.mean(payoff) * np.exp(-discount_rate * dt * num_steps)\n",
        "        option_values.append(option_value)\n",
        "        option_values_per_step[i] = payoff * np.exp(-discount_rate * dt * num_steps)\n",
        "    mean_option_value = np.mean(option_values)\n",
        "    return mean_option_value, prices_JP, prices_DE, transportation_costs, option_values_per_step\n",
        "\n",
        "jp_prices = combined_data['JKM'].tail(length)\n",
        "de_prices = combined_data['TTF'].tail(length)\n",
        "asia_prices = combined_data['Asia'].tail(length)\n",
        "\n",
        "theta_de, mu_de, sigma_de = estimate_parameters(de_prices, dt)\n",
        "theta_jp, mu_jp, sigma_jp = estimate_parameters(jp_prices, dt)\n",
        "theta_asia, mu_asia, sigma_asia = estimate_parameters(asia_prices, dt)\n",
        "\n",
        "\n",
        "print(\"Estimated Parameters for DE:\")\n",
        "print(\"Mean Reversion Strength (theta):\", theta_de)\n",
        "print(\"Long-Term Mean (mu):\", mu_de)\n",
        "print(\"Volatility (sigma):\", sigma_de)\n",
        "\n",
        "print(\"\\nEstimated Parameters for JP:\")\n",
        "print(\"Mean Reversion Strength (theta):\", theta_jp)\n",
        "print(\"Long-Term Mean (mu):\", mu_jp)\n",
        "print(\"Volatility (sigma):\", sigma_jp)\n",
        "\n",
        "print(\"\\nEstimated Parameters for transportation costs:\")\n",
        "print(\"Mean Reversion Strength (theta):\", theta_asia)\n",
        "print(\"Long-Term Mean (mu):\", mu_asia)\n",
        "print(\"Volatility (sigma):\", sigma_asia)\n",
        "\n",
        "\n",
        "option_value, prices_JP, prices_DE, simulated_transportation_costs, option_values_per_step = calculate_option_value(\n",
        "    [theta_jp, mu_jp, sigma_jp],\n",
        "    [theta_de, mu_de, sigma_de],\n",
        "    [theta_asia, mu_asia, sigma_asia],\n",
        "    jp_prices.iloc[-1], de_prices.iloc[-1], asia_prices.iloc[-1],\n",
        "    dt, length, num_simulations, discount_rate, correlation_matrix\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Value of the Destination Flexibility Option:\", option_value)\n",
        "print(\"Value of the Destination Flexibility Option %:\", (option_value/jp_prices.iloc[-1])*100)\n",
        "\n",
        "\n",
        "correlation_JP = np.corrcoef(prices_JP.flatten(), prices_DE.flatten())[0, 1]\n",
        "correlation_trans = np.corrcoef(simulated_transportation_costs.flatten(), prices_DE.flatten())[0, 1]\n",
        "print(\"Correlation between simulated DE and JP prices:\", correlation_JP)\n",
        "print(\"Correlation between simulated transport cost and JP prices:\", correlation_trans)\n",
        "\n",
        "prices_JP_flat = pd.Series(prices_JP.flatten())\n",
        "prices_DE_flat = pd.Series(prices_DE.flatten())\n",
        "\n",
        "\n",
        "\n",
        "# ###################PLOTTING#######################################################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "jp_actual_prices = combined_data['JKM'].tail(length).values\n",
        "de_actual_prices = combined_data['TTF'].tail(length).values\n",
        "asia_actual_prices = combined_data['Asia'].tail(length).values  # Actual transportation prices\n",
        "\n",
        "# Create a grid for the plots\n",
        "fig = plt.figure(figsize=(22, 8))\n",
        "gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1])\n",
        "\n",
        "ax0 = plt.subplot(gs[0])\n",
        "\n",
        "# Length of actual prices\n",
        "len_actual_prices = len(jp_actual_prices)\n",
        "\n",
        "# Plot actual prices first\n",
        "ax0.plot(range(len_actual_prices), jp_actual_prices, color='blue', label='Actual JKM Market', linewidth=2)\n",
        "ax0.plot(range(len_actual_prices), de_actual_prices, color='red', label='Actual TTF Market', linewidth=2)\n",
        "ax0.plot(range(len_actual_prices), asia_actual_prices, color='green', label='Actual Asia Transportation Cost', linewidth=2)\n",
        "\n",
        "# Plot simulated prices and transportation costs\n",
        "for i in range(100):\n",
        "    ax0.plot(range(len_actual_prices, len_actual_prices + len(prices_JP[i])), prices_JP[i], color='blue', alpha=0.05)\n",
        "    ax0.plot(range(len_actual_prices, len_actual_prices + len(prices_DE[i])), prices_DE[i], color='red', alpha=0.05)\n",
        "    ax0.plot(range(len_actual_prices, len_actual_prices + len(simulated_transportation_costs[i])), simulated_transportation_costs[i], color='green', alpha=0.05)\n",
        "\n",
        "# Plot the specific simulation with a thicker line\n",
        "random_index = np.random.randint(0, 100)\n",
        "ax0.plot(range(len_actual_prices, len_actual_prices + len(prices_JP[random_index])), prices_JP[random_index], color='black', linewidth=1, linestyle='--', label='Random JKM Simulation')\n",
        "ax0.plot(range(len_actual_prices, len_actual_prices + len(prices_DE[random_index])), prices_DE[random_index], color='grey', linewidth=1, linestyle='--', label='Random TTF Simulation')\n",
        "ax0.plot(range(len_actual_prices, len_actual_prices + len(simulated_transportation_costs[random_index])), simulated_transportation_costs[random_index], color='orange', linewidth=1, linestyle='--', label='Random Transportation Cost Simulation')\n",
        "\n",
        "ax0.set_title('Actual and Simulated Price Paths for Asian (JKM), European (TTF) Markets, and Asia Transportation Costs')\n",
        "ax0.set_xlabel('Time Steps')\n",
        "ax0.set_ylabel('Price')\n",
        "ax0.legend()\n",
        "\n",
        "# Create the combined distribution plot on the right\n",
        "ax1 = plt.subplot(gs[1], sharey=ax0)\n",
        "ax1.hist(prices_JP.flatten(), color='blue', orientation='horizontal', alpha=0.5, label='JKM Market', bins=50)\n",
        "ax1.hist(prices_DE.flatten(), color='red', orientation='horizontal', alpha=0.5, label='TTF Market', bins=50)\n",
        "ax1.hist(simulated_transportation_costs.flatten(), color='green', orientation='horizontal', alpha=0.5, label='Asia Transportation Cost', bins=50)\n",
        "ax1.set_xlabel('Frequency')\n",
        "ax1.legend()\n",
        "\n",
        "# ax0.set_ylim(bottom=0, top=400)\n",
        "# ax1.set_ylim(bottom=0, top=400)\n",
        "\n",
        "\n",
        "\n",
        "# Adjust the space between the plots\n",
        "plt.subplots_adjust(wspace=0.05)\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}